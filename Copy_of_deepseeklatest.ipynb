{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/archie-a18/zomato/blob/main/Copy_of_deepseeklatest.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------\n",
        "# STEP 1: INSTALL DEPENDENCIES\n",
        "# ----------------------------\n",
        "!apt-get update -y && apt-get install -y tesseract-ocr\n",
        "!pip install pytesseract sentence-transformers scikit-learn Pillow requests\n",
        "\n",
        "# ----------------------------\n",
        "# STEP 2: IMPORT LIBRARIES\n",
        "# ----------------------------\n",
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "import pytesseract\n",
        "import re\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# ----------------------------\n",
        "# STEP 3: CONFIGURATION\n",
        "# ----------------------------\n",
        "RESTAURANT_MENUS = {\n",
        "    \"Pukhtaan\": [\n",
        "        \"https://b.zmtcdn.com/data/menus/853/21580853/feb85f6fa20259fe481a7bc440c24476.jpg\",\n",
        "        \"https://b.zmtcdn.com/data/menus/853/21580853/10691ec61acb78405f5961a3d22a42f2.jpg\",\n",
        "        \"https://b.zmtcdn.com/data/menus/853/21580853/460c2011d7dfda6acf1be4dbf8a73da7.jpg\",\n",
        "        \"https://b.zmtcdn.com/data/menus/853/21580853/7e77459a125abd77aed34f7a882ad7e7.jpg\",\n",
        "        \"https://b.zmtcdn.com/data/menus/853/21580853/e08b90bf17c69fbe518c79c11ff6db7f.jpg\",\n",
        "        \"https://b.zmtcdn.com/data/menus/853/21580853/7672cc353331bd91ed471104de6192b5.jpg\",\n",
        "        \"https://b.zmtcdn.com/data/menus/853/21580853/d0f40d75623a98ebc9e8527c2bc0d5e6.jpg\",\n",
        "        \"https://b.zmtcdn.com/data/menus/853/21580853/ead678286bc10afb1f1a6c3bb94ecf10.jpg\",\n",
        "\n",
        "\n",
        "\n",
        "    ],\n",
        "     \"Connaught_Club_House\": [\n",
        "        \"https://b.zmtcdn.com/data/menus/106/19295106/faf36abd62cb22e25492a1e51d36d971.jpg\",\n",
        "    \"https://b.zmtcdn.com/data/menus/106/19295106/6d533623bfb316c927d5087a1be26f1b.jpg\",\n",
        "    \"https://b.zmtcdn.com/data/menus/106/19295106/92fdde9055013c6ab9ba7e9b76c1770d.jpg\",\n",
        "    \"https://b.zmtcdn.com/data/menus/106/19295106/d59c8c08538a220438fab471790d2b3b.jpg\",\n",
        "    \"https://b.zmtcdn.com/data/menus/106/19295106/d5ff7bf34e11499d79ee59b5492e892d.jpg\",\n",
        "    \"https://b.zmtcdn.com/data/menus/106/19295106/5757370e09010293de96576c65c499f3.jpg\",\n",
        "    \"https://b.zmtcdn.com/data/menus/106/19295106/e784555ca0fac7f4b2c78ad12d708108.jpg\",\n",
        "    \"https://b.zmtcdn.com/data/menus/106/19295106/cf56b2e45236ab81e3adeebde09937e5.jpg\",\n",
        "    \"https://b.zmtcdn.com/data/menus/106/19295106/b3a95e356d17115f48f31e488fa14510.jpg\",\n",
        "    \"https://b.zmtcdn.com/data/menus/106/19295106/db6351e453b6a553e2a95a029ccd5c93.jpg\",\n",
        "    \"https://b.zmtcdn.com/data/menus/106/19295106/63668b33e2cd94b084aba2400a32302d.jpg\",\n",
        "    \"https://b.zmtcdn.com/data/menus/106/19295106/28c47c6101f4b6525ae0f00054685f7b.jpg\",\n",
        "    \"https://b.zmtcdn.com/data/menus/106/19295106/8580a3bc941162b7ac0fcf6a2b29408f.jpg\",\n",
        "    \"https://b.zmtcdn.com/data/menus/106/19295106/9e199b47a96c620137325a2edaa257ea.jpg\",\n",
        "    \"https://b.zmtcdn.com/data/menus/106/19295106/a48b905eda7e351ec9d16be38263c6ce.jpg\",\n",
        "    \"https://b.zmtcdn.com/data/menus/106/19295106/e1256a12cfc8d2671887daf5849462c3.jpg\",\n",
        "    \"https://b.zmtcdn.com/data/menus/106/19295106/407cf6d0c92226a1e8d3c2e306bc7eee.jpg\",\n",
        "    \"https://b.zmtcdn.com/data/menus/106/19295106/a06bc4526e30e16cd66e7fc33680ddd1.jpg\",\n",
        "    \"https://b.zmtcdn.com/data/menus/106/19295106/f43d42f35215a54255c2b3c5e7bc361d.jpg\"\n",
        "],\n",
        "    \"Local\": [\n",
        "   \"https://b.zmtcdn.com/data/menus/360/18382360/4a261b83c8d83e45c90ba18738606383.jpg\",\n",
        "    \"https://b.zmtcdn.com/data/menus/360/18382360/e594cde054e3b9cd74bada9713d45647.jpg\",\n",
        "    \"https://b.zmtcdn.com/data/menus/360/18382360/09f07621c6c933873eaa0e3cc2d8cee6.jpg\",\n",
        "    \"https://b.zmtcdn.com/data/menus/360/18382360/9df0e7ea170f93df343a776cbb433b2e.jpg\",\n",
        "    \"https://b.zmtcdn.com/data/menus/360/18382360/c7a32dfe8174158daf3395a2d8a3122a.jpg\",\n",
        "    \"https://b.zmtcdn.com/data/menus/360/18382360/6213b5c0e0e6304b496aa40ec29ee7c0.jpg\",\n",
        "    \"https://b.zmtcdn.com/data/menus/360/18382360/62bb0f0ab165aed9aac2f07386be6ce0.jpg\",\n",
        "    \"https://b.zmtcdn.com/data/menus/360/18382360/9bb62a9813fd95783befe1f938dff819.jpg\",\n",
        "    \"https://b.zmtcdn.com/data/menus/360/18382360/39c8d9378a98634edad40bd2e21c8269.jpg\",\n",
        "    \"https://b.zmtcdn.com/data/menus/360/18382360/9059e84501429b654a3b187f8fa05f3b.jpg\"\n",
        "],\n",
        "    \"Roofberries\": [\n",
        "        \"https://b.zmtcdn.com/data/menus/098/20020098/2bee857f808bf90d3a339432e3a9a97a.jpg\",\n",
        "        \"https://b.zmtcdn.com/data/menus/098/20020098/177310b350732ea411fce4ee922ce00c.jpg\",\n",
        "        \"https://b.zmtcdn.com/data/menus/098/20020098/c96d1f09849034960eb591d821a9255e.jpg\",\n",
        "        \"https://b.zmtcdn.com/data/menus/098/20020098/8eba87e7fc2ba0a32cb8ca73ce72e159.jpg\",\n",
        "        \"https://b.zmtcdn.com/data/menus/098/20020098/331391a9f9e30a09b1fe30a87c89b088.jpg\",\n",
        "        \"https://b.zmtcdn.com/data/menus/098/20020098/4fbe208100d596c5239518143fef18be.jpg\",\n",
        "        \"https://b.zmtcdn.com/data/menus/098/20020098/e232cbceaa3ac5ac4d66f91a18156cb3.jpg\",\n",
        "        \"https://b.zmtcdn.com/data/menus/098/20020098/e232cbceaa3ac5ac4d66f91a18156cb3.jpg\",\n",
        "        \"https://b.zmtcdn.com/data/menus/098/20020098/9d27ecac94a5815f62fe77fed142996b.jpg\",\n",
        "        \"https://b.zmtcdn.com/data/menus/098/20020098/40787d97f1db990c4199bda163a3f006.jpg\",\n",
        "        \"https://b.zmtcdn.com/data/menus/098/20020098/ce5f056e39226e5d1cc705b197116fc0.jpg\"\n",
        "    ],\n",
        "    \"QEY\":[\n",
        "        \"https://b.zmtcdn.com/data/menus/303/21180303/5fee9979bef7ea53f215f1eff035a98f.jpg\",\n",
        "        \"https://b.zmtcdn.com/data/menus/303/21180303/4ab2a194e0ef6b0976e94d55401aa815.jpg\",\n",
        "        \"https://b.zmtcdn.com/data/menus/303/21180303/cf7fb24e217cf17bf8884e3415bb333c.jpg\",\n",
        "        \"https://b.zmtcdn.com/data/menus/303/21180303/81cdfc3844a6c8adf4df6703f58435cc.jpg\",\n",
        "        \"https://b.zmtcdn.com/data/menus/303/21180303/a1843c6cc22ea5a9a8e00ae79e75fdf2.jpg\",\n",
        "        \"https://b.zmtcdn.com/data/menus/303/21180303/8466ea20afd3ba86a4742cd77b438def.jpg\",\n",
        "        \"https://b.zmtcdn.com/data/menus/303/21180303/8466ea20afd3ba86a4742cd77b438def.jpg\",\n",
        "        \"https://b.zmtcdn.com/data/menus/303/21180303/400e7dbc0b344795a3e937d0f3b7e07e.jpg\",\n",
        "        \"https://b.zmtcdn.com/data/menus/303/21180303/035bdb561621fc8ab19a89561e13f977.jpg\",\n",
        "        \"https://b.zmtcdn.com/data/menus/303/21180303/035bdb561621fc8ab19a89561e13f977.jpg\",\n",
        "        \"https://b.zmtcdn.com/data/menus/303/21180303/6f9151dff3d95c75f045151497b38fe9.jpg\",\n",
        "        \"https://b.zmtcdn.com/data/menus/303/21180303/48ba28da967d96653d8255d4197988c1.jpg\",\n",
        "        \"https://b.zmtcdn.com/data/menus/303/21180303/60b2ac9ef657dde53df1bf3026ab7083.jpg\",\n",
        "        \"https://b.zmtcdn.com/data/menus/303/21180303/73b22be7bae1ac5650e1ee9084a186ac.jpg\",\n",
        "        \"https://b.zmtcdn.com/data/menus/303/21180303/facad6ef851470f4313c134f2e59265e.jpg\",\n",
        "        \"https://b.zmtcdn.com/data/menus/303/21180303/8afaa475084fc676f842ec067f4888fb.jpg\",\n",
        "        \"https://b.zmtcdn.com/data/menus/303/21180303/fde5ab708e230a214ea2b0defa1f3f1a.jpg\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "# ----------------------------\n",
        "# STEP 4: OCR FUNCTIONS\n",
        "# ----------------------------\n",
        "def extract_text_from_image_url(image_url):\n",
        "    try:\n",
        "        response = requests.get(image_url, timeout=10)\n",
        "        response.raise_for_status()\n",
        "        image = Image.open(BytesIO(response.content))\n",
        "        return pytesseract.image_to_string(image)\n",
        "    except Exception as e:\n",
        "        print(f\"âš ï¸ Error processing {image_url}: {str(e)}\")\n",
        "        return \"\"\n",
        "\n",
        "def clean_ocr_text(text):\n",
        "    text = re.sub(r'[^a-zA-Z0-9\\s\\.,â‚¹$â‚¬Â¥Â¢&+()-]', '', text)\n",
        "    replacements = {\n",
        "        r'\\bOe\\b': 'Of', r'\\bee\\b': 'and',\n",
        "        r'\\bBe ary\\b': 'Biryani', r'\\bR (\\d+)': r'â‚¹\\1',\n",
        "        r'\\b(\\d+)\\s*-\\s*(\\d+)\\b': r'â‚¹\\1-\\2'\n",
        "    }\n",
        "    for pattern, replacement in replacements.items():\n",
        "        text = re.sub(pattern, replacement, text)\n",
        "    return text\n",
        "\n",
        "# ----------------------------\n",
        "# STEP 5: ENHANCED MENU PARSER\n",
        "# ----------------------------\n",
        "def parse_menu_from_ocr_text(ocr_text):\n",
        "    lines = [line.strip() for line in clean_ocr_text(ocr_text).split(\"\\n\") if line.strip()]\n",
        "    items = []\n",
        "    current_item = None\n",
        "    description_buffer = []\n",
        "\n",
        "    price_pattern = re.compile(\n",
        "        r'(?:â‚¹|Rs?\\.?|INR|MRP|Price)\\s*(\\d{1,3}(?:,\\d{3})*(?:\\.\\d{2})?)|'\n",
        "        r'(?:USD|$|Price)\\s*(\\d+\\.\\d{2})',\n",
        "        re.IGNORECASE\n",
        "    )\n",
        "\n",
        "    dietary_config = {\n",
        "        'vegetarian': ['vegetarian', 'veg', 'paneer', 'tofu', 'cheese'],\n",
        "        'non-vegetarian': ['non-vegetarian','non veg','chicken', 'mutton', 'fish', 'prawn', 'meat', 'lamb', 'beef', 'egg'],\n",
        "        'gluten-free': ['gluten-free', 'gluten free', 'gf'],\n",
        "        'vegan': ['vegan', 'dairy-free']\n",
        "    }\n",
        "\n",
        "    for line in lines:\n",
        "        # Detect price and item separators first\n",
        "        if handle_price_line(line, price_pattern, items, current_item, description_buffer):\n",
        "            current_item = None\n",
        "            continue\n",
        "\n",
        "        if is_new_item(line):\n",
        "            if current_item:\n",
        "                finalize_item(current_item, description_buffer, dietary_config, items)\n",
        "            current_item = create_new_item(line)\n",
        "            description_buffer = []\n",
        "        elif current_item:\n",
        "            description_buffer.append(line)\n",
        "\n",
        "    # Handle final item\n",
        "    if current_item:\n",
        "        finalize_item(current_item, description_buffer, dietary_config, items)\n",
        "\n",
        "    return split_combined_items(items)\n",
        "\n",
        "def handle_price_line(line, price_pattern, items, current_item, description_buffer):\n",
        "    \"\"\"Process lines containing prices\"\"\"\n",
        "    price_match = price_pattern.search(line)\n",
        "    if not price_match:\n",
        "        return False\n",
        "\n",
        "    price = price_match.group().replace(\"R \", \"â‚¹\").strip()\n",
        "    line = price_pattern.sub('', line).strip()\n",
        "\n",
        "    if current_item:\n",
        "        current_item['price'] = price\n",
        "        if line: description_buffer.append(line)\n",
        "        return True\n",
        "\n",
        "    if items and not items[-1]['price']:\n",
        "        items[-1]['price'] = price\n",
        "        if line: items[-1]['description'] += ' ' + line\n",
        "        return True\n",
        "\n",
        "    return False\n",
        "\n",
        "def is_new_item(line):\n",
        "    \"\"\"Improved item detection logic\"\"\"\n",
        "    return (len(line) > 3 and\n",
        "            line[0].isupper() and\n",
        "            sum(1 for c in line if c.isupper()) > len(line)//2 and\n",
        "            not any(c.isdigit() for c in line))\n",
        "\n",
        "def create_new_item(name):\n",
        "    return {'name': name, 'price': '', 'description': '', 'dietary': [], 'spice_level': 0}\n",
        "\n",
        "def finalize_item(item, description_buffer, dietary_config, items):\n",
        "    \"\"\"Complete item processing\"\"\"\n",
        "    item['description'] = ' '.join(description_buffer)\n",
        "    item['dietary'] = detect_dietary_tags(item, dietary_config)\n",
        "    item['spice_level'] = detect_spice_level(item['description'])\n",
        "    items.append(item.copy())\n",
        "\n",
        "# ----------------------------\n",
        "# STEP 6: POST-PROCESSING\n",
        "# ----------------------------\n",
        "def split_combined_items(items):\n",
        "    \"\"\"Fix combined items in descriptions\"\"\"\n",
        "    cleaned_items = []\n",
        "    for item in items:\n",
        "        parts = re.split(r'\\b(\\d{3,4})\\b', item['description'])\n",
        "        if len(parts) > 1:\n",
        "            for i in range(0, len(parts)-1, 2):\n",
        "                new_item = item.copy()\n",
        "                new_item['description'] = parts[i].strip()\n",
        "                if i+1 < len(parts):\n",
        "                    new_item['price'] = f\"â‚¹{parts[i+1].strip()}\"\n",
        "                cleaned_items.append(new_item)\n",
        "        else:\n",
        "            cleaned_items.append(item)\n",
        "    return cleaned_items\n",
        "\n",
        "def detect_dietary_tags(item, config):\n",
        "    text = f\"{item['name']} {item['description']}\".lower()\n",
        "    tags = []\n",
        "    if any(kw in text for kw in config['non-vegetarian']):\n",
        "        tags.append('non-vegetarian')\n",
        "    for category, keywords in config.items():\n",
        "        if category == 'non-vegetarian': continue\n",
        "        if any(kw in text for kw in keywords):\n",
        "            tags.append(category)\n",
        "    return tags\n",
        "\n",
        "def detect_spice_level(description):\n",
        "    text = description.lower()\n",
        "    spice_levels = {\n",
        "        3: ['extra spicy', 'fiery', 'blazing'],\n",
        "        2: ['spicy', 'chilli', 'hot'],\n",
        "        1: ['mild', 'light spice']\n",
        "    }\n",
        "    for level, keywords in spice_levels.items():\n",
        "        if any(kw in text for kw in keywords):\n",
        "            return level\n",
        "    return 0\n",
        "\n",
        "# ----------------------------\n",
        "# STEP 7: DATA PROCESSING\n",
        "# ----------------------------\n",
        "def process_restaurant_menus(restaurant_name, menu_urls):\n",
        "    all_text = []\n",
        "    for url in menu_urls:\n",
        "        print(f\"Processing {restaurant_name} menu: {url[-20:]}\")\n",
        "        all_text.append(extract_text_from_image_url(url))\n",
        "    return parse_menu_from_ocr_text(\"\\n\\n\".join(all_text))\n",
        "\n",
        "def prepare_embeddings(restaurant_data):\n",
        "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "    for name, data in restaurant_data.items():\n",
        "        corpus = [f\"{item['name']} {item['description']}\" for item in data['items']]\n",
        "        data['embeddings'] = model.encode(corpus) if corpus else None\n",
        "    return restaurant_data\n",
        "\n",
        "# ----------------------------\n",
        "# STEP 8: SEARCH ENGINE\n",
        "# ----------------------------\n",
        "def enhanced_search(query, restaurant_data, top_k=5):\n",
        "    results = []\n",
        "    model = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "\n",
        "    # Extract price filter\n",
        "    price_filter = re.search(r'under â‚¹?(\\d+)', query, re.IGNORECASE)\n",
        "    max_price = int(price_filter.group(1)) if price_filter else None\n",
        "\n",
        "    for rest_name, data in restaurant_data.items():\n",
        "        # Handle restaurant-specific queries\n",
        "        if ' in ' in query.lower():\n",
        "            query_part, _, rest_part = query.lower().partition(' in ')\n",
        "            if rest_name.lower() not in rest_part: continue\n",
        "            query = query_part\n",
        "\n",
        "        for idx, item in enumerate(data['items']):\n",
        "            # Price validation\n",
        "            price = extract_price(item['price']) or extract_price(item['description'])\n",
        "            if max_price and (price or 9999) > max_price: continue\n",
        "\n",
        "            # Calculate relevance score\n",
        "            if query.lower() in item['name'].lower():\n",
        "                score = 1.0\n",
        "            else:\n",
        "                query_emb = model.encode([query])\n",
        "                item_emb = model.encode([f\"{item['name']} {item['description']}\"])\n",
        "                score = cosine_similarity(query_emb, item_emb)[0][0]\n",
        "\n",
        "            # Spice level filter\n",
        "            if 'spicy' in query.lower() and item['spice_level'] < 1: continue\n",
        "\n",
        "            results.append({\n",
        "                'name': item['name'],\n",
        "                'price': format_price(item['price']),\n",
        "                'description': item['description'],\n",
        "                'dietary': item['dietary'],\n",
        "                'spice_level': item['spice_level'],\n",
        "                'restaurant': rest_name,\n",
        "                'score': score\n",
        "            })\n",
        "\n",
        "    return sorted(results, key=lambda x: x['score'], reverse=True)[:top_k]\n",
        "\n",
        "def extract_price(text):\n",
        "    matches = re.findall(r'\\d{3,4}', text)\n",
        "    return int(matches[-1]) if matches else None\n",
        "\n",
        "def format_price(price_str):\n",
        "    if not price_str: return \"Check price\"\n",
        "    clean_price = re.sub(r'[^0-9]', '', price_str)\n",
        "    return f\"â‚¹{int(clean_price):,}\" if clean_price else \"Check price\"\n",
        "\n",
        "# ----------------------------\n",
        "# STEP 9: USER INTERFACE\n",
        "# ----------------------------\n",
        "def display_results(results):\n",
        "    if not results:\n",
        "        print(\"\\nğŸ” No matching dishes found. Try different keywords!\")\n",
        "        return\n",
        "\n",
        "    print(\"\\nğŸ½ï¸ Top Results:\")\n",
        "    for idx, item in enumerate(results, 1):\n",
        "        print(f\"\\n{idx}. {item['name']} @ {item['restaurant']}\")\n",
        "        print(f\"   ğŸ’µ Price: {item['price']}\")\n",
        "        print(f\"   ğŸŒ¶ï¸ Spice: {'â˜…' * item['spice_level']}{'â˜†' * (3 - item['spice_level'])}\")\n",
        "        print(f\"   ğŸ¥— Dietary: {', '.join(item['dietary']) or 'Not specified'}\")\n",
        "        if item['description']:\n",
        "            print(f\"   ğŸ“ Description: {item['description'][:100]}...\")\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "\n",
        "def restaurant_chatbot(restaurant_data):\n",
        "    print(\"\\nğŸ´ Welcome to Food Explorer!\")\n",
        "    print(\"Ask about dishes (e.g., 'spicy vegetarian under â‚¹500', 'non-vegetarian in Local', or 'exit')\")\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            query = input(\"\\nYou: \").strip()\n",
        "            if query.lower() in ('exit', 'quit'):\n",
        "                print(\"\\nğŸ‘‹ Thank you for using Food Explorer!\")\n",
        "                break\n",
        "\n",
        "            results = enhanced_search(query, restaurant_data)\n",
        "            display_results(results)\n",
        "\n",
        "        except KeyboardInterrupt:\n",
        "            print(\"\\nğŸ‘‹ Session ended by user\")\n",
        "            break\n",
        "        except Exception as e:\n",
        "            print(f\"\\nâš ï¸ Error processing request: {str(e)}\")\n",
        "\n",
        "# ----------------------------\n",
        "# STEP 10: MAIN EXECUTION\n",
        "# ----------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    # Data processing pipeline\n",
        "    restaurant_data = {}\n",
        "    for name, urls in RESTAURANT_MENUS.items():\n",
        "        items = process_restaurant_menus(name, urls)\n",
        "        restaurant_data[name] = {'items': items, 'embeddings': None}\n",
        "        print(f\"\\nâœ… {name}: Processed {len(items)} menu items\")\n",
        "\n",
        "    # Prepare semantic embeddings\n",
        "    restaurant_data = prepare_embeddings(restaurant_data)\n",
        "\n",
        "    # Start interactive chatbot\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AMdcURlzzyO2",
        "outputId": "51dad4c6-a1b1-4ec4-9981-d6c68ce8a282"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease\n",
            "Hit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Hit:3 http://security.ubuntu.com/ubuntu jammy-security InRelease\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Hit:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease\n",
            "Hit:7 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "tesseract-ocr is already the newest version (4.1.1-2.1build1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n",
            "Requirement already satisfied: pytesseract in /usr/local/lib/python3.11/dist-packages (0.3.13)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (11.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (24.2)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.51.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.14.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.1.31)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Processing Pukhtaan menu: 481a7bc440c24476.jpg\n",
            "Processing Pukhtaan menu: 5f5961a3d22a42f2.jpg\n",
            "Processing Pukhtaan menu: cf1be4dbf8a73da7.jpg\n",
            "Processing Pukhtaan menu: aed34f7a882ad7e7.jpg\n",
            "Processing Pukhtaan menu: 518c79c11ff6db7f.jpg\n",
            "Processing Pukhtaan menu: ed471104de6192b5.jpg\n",
            "Processing Pukhtaan menu: c9e8527c2bc0d5e6.jpg\n",
            "Processing Pukhtaan menu: 1f1a6c3bb94ecf10.jpg\n",
            "\n",
            "âœ… Pukhtaan: Processed 104 menu items\n",
            "Processing Connaught_Club_House menu: 5492a1e51d36d971.jpg\n",
            "Processing Connaught_Club_House menu: 27d5087a1be26f1b.jpg\n",
            "Processing Connaught_Club_House menu: b9ba7e9b76c1770d.jpg\n",
            "Processing Connaught_Club_House menu: 38fab471790d2b3b.jpg\n",
            "Processing Connaught_Club_House menu: 79ee59b5492e892d.jpg\n",
            "Processing Connaught_Club_House menu: de96576c65c499f3.jpg\n",
            "Processing Connaught_Club_House menu: b2c78ad12d708108.jpg\n",
            "Processing Connaught_Club_House menu: e3adeebde09937e5.jpg\n",
            "Processing Connaught_Club_House menu: 48f31e488fa14510.jpg\n",
            "Processing Connaught_Club_House menu: e2a95a029ccd5c93.jpg\n",
            "Processing Connaught_Club_House menu: 84aba2400a32302d.jpg\n",
            "Processing Connaught_Club_House menu: 5ae0f00054685f7b.jpg\n",
            "Processing Connaught_Club_House menu: ac0fcf6a2b29408f.jpg\n",
            "Processing Connaught_Club_House menu: 37325a2edaa257ea.jpg\n",
            "Processing Connaught_Club_House menu: c9d16be38263c6ce.jpg\n",
            "Processing Connaught_Club_House menu: 1887daf5849462c3.jpg\n",
            "Processing Connaught_Club_House menu: e8d3c2e306bc7eee.jpg\n",
            "Processing Connaught_Club_House menu: d66e7fc33680ddd1.jpg\n",
            "Processing Connaught_Club_House menu: 55c2b3c5e7bc361d.jpg\n",
            "\n",
            "âœ… Connaught_Club_House: Processed 348 menu items\n",
            "Processing Local menu: c90ba18738606383.jpg\n",
            "Processing Local menu: 74bada9713d45647.jpg\n",
            "Processing Local menu: 3eaa0e3cc2d8cee6.jpg\n",
            "Processing Local menu: 343a776cbb433b2e.jpg\n",
            "Processing Local menu: af3395a2d8a3122a.jpg\n",
            "Processing Local menu: 496aa40ec29ee7c0.jpg\n",
            "Processing Local menu: aac2f07386be6ce0.jpg\n",
            "Processing Local menu: 3befe1f938dff819.jpg\n",
            "Processing Local menu: dad40bd2e21c8269.jpg\n",
            "Processing Local menu: 4a3b187f8fa05f3b.jpg\n",
            "\n",
            "âœ… Local: Processed 204 menu items\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"ğŸš€ System Ready for Queries!\")\n",
        "    print(\"=\"*60)\n",
        "    restaurant_chatbot(restaurant_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iUGZo74IziFp",
        "outputId": "374ff47d-4438-4b0b-b7a5-3afff3ed44cb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "ğŸš€ System Ready for Queries!\n",
            "============================================================\n",
            "\n",
            "ğŸ´ Welcome to Food Explorer!\n",
            "Ask about dishes (e.g., 'spicy vegetarian under â‚¹500', 'non-vegetarian in Local', or 'exit')\n",
            "\n",
            "You: vegetarian dishes\n",
            "\n",
            "ğŸ½ï¸ Top Results:\n",
            "\n",
            "1. Our Cch Special Homemade Veggie Patty, Special Sauce, Cheddar Cheese, @ Connaught_Club_House\n",
            "   ğŸ’µ Price: Check price\n",
            "   ğŸŒ¶ï¸ Spice: â˜†â˜†â˜†\n",
            "   ğŸ¥— Dietary: vegetarian\n",
            "\n",
            "2. Homemade Veggie Patty, Sauteed Fresh Mushrooms, Special Sauce, Cheddar Cheese. @ Connaught_Club_House\n",
            "   ğŸ’µ Price: Check price\n",
            "   ğŸŒ¶ï¸ Spice: â˜†â˜†â˜†\n",
            "   ğŸ¥— Dietary: vegetarian\n",
            "\n",
            "3. Pomodoro Sauce,Mozarella Cheese,Confit Tomatoes And Basil Leaves @ Local\n",
            "   ğŸ’µ Price: Check price\n",
            "   ğŸŒ¶ï¸ Spice: â˜†â˜†â˜†\n",
            "   ğŸ¥— Dietary: vegetarian\n",
            "   ğŸ“ Description: e) GARDEN VEGETABLE...\n",
            "\n",
            "4. Spices And Stuffed With Cheese @ Local\n",
            "   ğŸ’µ Price: Check price\n",
            "   ğŸŒ¶ï¸ Spice: â˜†â˜†â˜†\n",
            "   ğŸ¥— Dietary: vegetarian\n",
            "   ğŸ“ Description: ie DAHI KEBAB...\n",
            "\n",
            "5. Cheese Served With Herb Rice @ Connaught_Club_House\n",
            "   ğŸ’µ Price: Check price\n",
            "   ğŸŒ¶ï¸ Spice: â˜†â˜†â˜†\n",
            "   ğŸ¥— Dietary: vegetarian\n",
            "\n",
            "============================================================\n",
            "\n",
            "You: spicy vegetarian dishes\n",
            "\n",
            "ğŸ½ï¸ Top Results:\n",
            "\n",
            "1. Crispy Corn Salt And Pepper @ Local\n",
            "   ğŸ’µ Price: Check price\n",
            "   ğŸŒ¶ï¸ Spice: â˜…â˜…â˜†\n",
            "   ğŸ¥— Dietary: vegetarian\n",
            "   ğŸ“ Description: Â¢ STIR FRY MUSHROOMS,FRESH CHILLI AND PEPPERS (Â¢ BEIJING STYLE CRISPY TOFU & CELERY PIMENTO PEPPERS ...\n",
            "\n",
            "============================================================\n",
            "\n",
            "You: non-vegetarian dishes\n",
            "\n",
            "ğŸ” No matching dishes found. Try different keywords!\n",
            "\n",
            "You: non veg dishes\n",
            "\n",
            "ğŸ½ï¸ Top Results:\n",
            "\n",
            "1. Meal Accompaniments @ Connaught_Club_House\n",
            "   ğŸ’µ Price: Check price\n",
            "   ğŸŒ¶ï¸ Spice: â˜†â˜†â˜†\n",
            "   ğŸ¥— Dietary: Not specified\n",
            "\n",
            "2. Grilled Veggie Quesadilla @ Connaught_Club_House\n",
            "   ğŸ’µ Price: Check price\n",
            "   ğŸŒ¶ï¸ Spice: â˜†â˜†â˜†\n",
            "   ğŸ¥— Dietary: Not specified\n",
            "\n",
            "3. Our Cch Special Homemade Veggie Patty, Special Sauce, Cheddar Cheese, @ Connaught_Club_House\n",
            "   ğŸ’µ Price: Check price\n",
            "   ğŸŒ¶ï¸ Spice: â˜†â˜†â˜†\n",
            "   ğŸ¥— Dietary: vegetarian\n",
            "\n",
            "4. Homemade Veggie Patty, Sauteed Fresh Mushrooms, Special Sauce, Cheddar Cheese. @ Connaught_Club_House\n",
            "   ğŸ’µ Price: Check price\n",
            "   ğŸŒ¶ï¸ Spice: â˜†â˜†â˜†\n",
            "   ğŸ¥— Dietary: vegetarian\n",
            "\n",
            "5. Veggies,Cilantro,Green Onion And Santa Fe Sauce @ Local\n",
            "   ğŸ’µ Price: Check price\n",
            "   ğŸŒ¶ï¸ Spice: â˜†â˜†â˜†\n",
            "   ğŸ¥— Dietary: Not specified\n",
            "\n",
            "============================================================\n",
            "\n",
            "You: exit\n",
            "\n",
            "ğŸ‘‹ Thank you for using Food Explorer!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8uA0ByX9znJQ"
      },
      "execution_count": 2,
      "outputs": []
    }
  ]
}